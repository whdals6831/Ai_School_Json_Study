{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7FHW2aXqgpD",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 지도학습 - K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBkqsU34qj51",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "지도 학습 (Supervised Learning)\n",
    "- 데이터에 대한 Label(명시적인 답)이 주어진 상태에서 컴퓨터를 학습시키는 방법. \n",
    "\n",
    "비지도 학습 (Unsupervised Learning)\n",
    "- 데이터에 대한 Label(명시적인 답)이 없는 상태에서 컴퓨터를 학습시키는 방법.\n",
    "- 데이터의 숨겨진 특성이나 구조를 파악하는데 사용.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ouQU5jqTq32L",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "분류 (Classification)\n",
    "- 미리 정의된 여러 클래스 레이블 중 하나를 예측하는 것.\n",
    "- 속성 값을 입력, 클래스 값을 출력으로 하는 모델\n",
    "- 붓꽃(iris)의 세 품종 중 하나로 분류, 암 분류 등. \n",
    "- 이진분류, 다중 분류 등이 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrluIpUfrAtR",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "회귀 (Regression)\n",
    "- 연속적인 숫자를 예측하는 것.\n",
    "- 속성 값을 입력, 연속적인 실수 값을 출력으로 하는 모델\n",
    "- 어떤 사람의 교육수준, 나이, 주거지를 바탕으로 연간 소득 예측. \n",
    "- 예측 값의 미묘한 차이가 크게 중요하지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YbqjV135rRz3",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "일반화, 과대적합, 과소적합\n",
    "\n",
    "일반화 (Generalization)\n",
    "- 모델이 처음보는 데이터에 대해 정확하게 예측할 수 있는 것.\n",
    "- 훈련 세트로 학습한 모델이 테스트 세트에 대해 정확히 예측 하도록 하는 것.\n",
    "\n",
    "과대적합 (Overfitting)\n",
    "- 훈련 세트에 너무 맞추어져 있어 테스트 세트의 성능 저하.\n",
    "\n",
    "과소적합 (Underfitting)\n",
    "- 훈련 세트를 충분히 반영하지 못해 훈련 세트, 테스트 세트에서 모두 성능이 저하.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pipeajPbtrP6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***일반화 성능이 최대화 되는 모델을 찾는 것이 목표***\n",
    "\n",
    "과대적합 (Overfitting)\n",
    "- 모델이 훈련 세트의 각 샘플에 너무 가깝게 맞춰져서 새로운 데이터에 일반화되기 어려울 때.\n",
    "- 가진 정보를 모두 사용해서 너무 복잡한 모델을 만드는 것.\n",
    "\n",
    "과소적합 (Underfitting)\n",
    "- 모델링을 너무 간단하게 하여 성능이 제대로 나오지 않을 때.\n",
    "- 데이터의 다양성을 잡아내지 못하고, 훈련 세트에도 잘 맞지 않는 너무 간단한 모델을 만드는 것.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhOpHopIvpnt",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "해결방법\n",
    "\n",
    "- 주어진 훈련데이터의 다양성이 보장되어야 한다 (다양한 데이터 포인트를 골고루 나타내야 한다)\n",
    "- 일반적으로 데이터 양이 많으면 일반화에 도움이 된다.\n",
    "- 그러나 편중된 데이터를 많이 모으는 것은 도움이 되지 않는다.\n",
    "- 규제([Regularization](https://developers.google.com/machine-learning/glossary#L1_regularization))을 통해 모델의 복잡도를 적정선으로 설정한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FnUQR0YBv9Z2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-Nearest Neighbors (KNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jx5_DzFGwDwy",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "k-최근접 이웃 알고리즘\n",
    "\n",
    "- 새로운 데이터 포인트와 가장 가까운 훈련 데이터세트의 데이터 포인트를 찾아 예측\n",
    "- k 값에 따라 가까운 이웃의 수가 결정\n",
    "- 분류와 회귀에 모두 사용 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nq47kaWj0i-Q",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 입력 값과 k개의 가까운 점이 있다고 가정할 때 그 점들이 어떤 라벨과 가장 비슷한지 (최근접 이웃)\n",
    "판단하는 알고리즘\n",
    "\n",
    "- 매개 변수 : 데이터 포인트 사이의 거리를 재는 방법 (일반적으로 유클리디안 거리를 이용), 이웃의 수\n",
    " - 장점 : 이해하기 쉬운 모델, 약간의 조정으로 좋은 성능\n",
    " - 단점 : 훈련 세트가 크면 속도가 느림, 많은 특성을 처리하기 힘듬."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hyw6-dEJyjAg",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- k 값이 작을 수록 모델의 복잡도가 상대적으로 증가. (이웃을 적게 사용하면)\n",
    "- 반대로 k 값이 커질수록 모델의 복잡도가 낮아진다. (이웃을 많이 사용하면)\n",
    "- 100개의 데이터를 학습하고, k를 100개로 설정하여 예측하면 빈도가 가장 많은 클래스 레이블로 분류\n",
    " (훈련 데이터 전체 개수를 이웃의 수로 지정하는 극단적인 경우)\n",
    " \n",
    " [KNeighborsClassifier 분석](ml_02_%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5_KNN.ipynb#KNeighborsClassifier-%EB%B6%84%EC%84%9D) 참고\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4GRWtfyd08q4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "유클리디안 거리 (Euclidean distance) : 두 점사이의 거리를 계산할 때 쓰이는 방법\n",
    "- 두 점 (p1, p2, ...)와 (q1, q2, ....)의 거리\n",
    "\n",
    "<center>\n",
    " <img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F242971445236215901\" alt=\"유클리디안 거리 공식\" width=\"60%\" />\n",
    "\n",
    "유클리디안 거리 공식\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ys5Y_SnQxqMG",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "KNeighborsClassifier()\n",
    "```\n",
    "KNeighborsClassifier(n_neighbors, weights, algorithm, leaf_size, p, metric, metric_params, n_jobs)\n",
    "```\n",
    "- n_neighbors : 이웃의 수 (default : 5)\n",
    "- weights : 예측에 사용된 가중 함수 (uniform, distance) (default : uniform)\n",
    "- algorithm : 가까운 이웃을 계산하는데 사용되는 알고리즘 (auto, ball_tree, kd_tree, brute)\n",
    "- leaf_size : BallTree 또는 KDTree에 전달 된 리프 크기\n",
    "- p : (1 : minkowski_distance, 2: manhattan_distance 및 euclidean_distance)\n",
    "- metric : 트리에 사용하는 거리 메트릭스\n",
    "- metric_params : 메트릭 함수에 대한 추가 키워드 인수\n",
    "- n_jobs : 이웃 검색을 위해 실행할 병렬 작업 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_dgm3wNkYsQ",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "KNeighborsClassifier 모델은 k-최근접 이웃 분류 또는 KNN이라고 합니다. <br>\n",
    "k-NN 알고리즘은 가장 가까운 훈련 데이터 포인트 K개를 최근접 이웃으로 찾아 예측에 사용합니다. <br>\n",
    "n_neighbors=1 는 1개를 최근접 이웃으로 하겠다는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gckNe5VR2gXJ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "주요 매개변수(Hyperparameter)\n",
    "- 거리측정 방법, 이웃의 수, 가중치 함수 \n",
    "\n",
    "scikit-learn의 경우\n",
    "- metric  :  유클리디언 거리 방식\n",
    "- k : 이웃의 수\n",
    "- weight  : 가중치 함수\n",
    "     -  uniform : 가중치를 동등하게 설정.\n",
    "     -  distance :  가중치를 거리에 반비례하도록 설정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qp2ass6k26KD",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "장단점\n",
    "- 이해하기 매우 쉬운 모델\n",
    "- 훈련 데이터 세트가 크면(특성,샘플의 수) 예측이 느려진다\n",
    "- 수백 개 이상의 많은 특성을 가진 데이터 세트와 특성 값 대부분이 0인 희소(sparse)한 데이터 세트에는 잘 동작하지 않는다\n",
    "- 거리를 측정하기 때문에 같은 scale을 같도록 정규화 필요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXE4MqWcyEi5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### iris 데이터를 이용한 KNN 분류 실습\n",
    "\n",
    "붓꽃 데이터 셋\n",
    "- 클래스 (class) : 출력될 수 있는 값 (붓꽃의 종류)\n",
    "- 레이블 (label) : 특정 데이터 포인트에 대한 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUCS-d4y4PM2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "붓꽃 (Iris)의 품종 분류\n",
    "\n",
    "<center>\n",
    " <img src=\"https://thegoodpython.com/assets/images/iris-species.png\" alt=\"붓꽃 품종\" width=\"60%\" />\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZ1kjzM84GQj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 사이킷 런 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1211,
     "status": "ok",
     "timestamp": 1594825314158,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "t90gItOQqIRN",
    "outputId": "d7db27f9-3721-4406-e932-6072b24e4a55",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "(150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "(150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 가져오기\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "iris_dataset\n",
    "type(iris_dataset)  # sklearn.utils.Bunch -> 파이썬의 딕셔너리와 유사한 키와 값으로 구성\n",
    "\n",
    "iris_dataset.keys() # 'data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'\n",
    "# print( iris_dataset['DESCR'] )  # 데이터셋 간략 설명\n",
    "print( iris_dataset.target_names ) # 예측하려는 붓꽃 품종 이름 리스트\n",
    "print( iris_dataset.feature_names) # 각 특성을 설명하는 문자열 리스트\n",
    "print( iris_dataset.data.shape )   # 꽃잎의 길이와 폭, 꽃받침의 길이와 폭 값을 갖는 ndarray\n",
    "                                   # 머신러닝에서 각 아이템은 샘플, 속성은 특성\n",
    "print( iris_dataset.data[:5] )     # 처음 5개만 출력\n",
    "print( iris_dataset.target.shape ) # 샘플 붓꽃의 품종을 담은 ndarray, 1차원 배열\n",
    "print( iris_dataset.target )       # 붓꽃 종류 0~2 정수로 기록 (0은 setosa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ji1sWjnX2l75",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### seaborn 이용\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1594823948610,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "P3bMeHO92szF",
    "outputId": "2dcc3bab-ae02-4e4e-f8fe-3d25c196c5f9",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 가져오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# iris data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 991,
     "status": "ok",
     "timestamp": 1594822990182,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "ONXmdHNQ22YG",
    "outputId": "5d3a45e5-a4ca-40cf-be5e-12d9c9f55539",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxUgFRHU5Oxd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "훈련 세트(training set) <br>\n",
    "테스트 세트(test set), 홀드아웃 세트(hold-out set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1068,
     "status": "ok",
     "timestamp": 1594824611169,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "pNxQ1avJ6BrL",
    "outputId": "584f9238-13ea-4848-a544-3f4ac428e734",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# data\n",
    "# label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1210,
     "status": "ok",
     "timestamp": 1594824618762,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "nMcuTLjW4Wjv",
    "outputId": "9a0aff75-83d3-45bb-82ab-242c4a77addf",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터 준비\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 2차원 배열(행렬)의 수학 표기방식 대문자 X\n",
    "# 1차원 배열(벡터)의 수학 표기방식 소문자 y\n",
    "# 데이터 섞음\n",
    "\n",
    "# 75% : 25%\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5120,
     "status": "ok",
     "timestamp": 1594824627358,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "AwgsCYG12_NO",
    "outputId": "8e4d0bbc-b53a-468d-b01b-06aa552fefbf",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 조사\n",
    "# 산점도 행렬 : 3개 이상의 특성을 표현\n",
    "# 4개의 특성을 갖는 붓꽃\n",
    "# 대각원소 자리에 각 변수별 히스토그램\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6684,
     "status": "ok",
     "timestamp": 1594824644042,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "efM9lByf3J-p",
    "outputId": "230240cd-33cf-4f90-89b9-050d1fd50de1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Scatterplot matrix with different color by group and kde\n",
    "\n",
    "# 각 변수별 커널밀도추정곡선\n",
    "# 'species' 종(setosa, versicolor, virginica) 별로 색깔을 다르게 표시\n",
    "# pastel, bright, deep, muted, colorblind, dark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5OFhJgG2AUZV",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 공통"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 849,
     "status": "ok",
     "timestamp": 1594825334336,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "MSNd6f24677o",
    "outputId": "ef2fbdab-3cbf-4a08-cd86-b9d2b6933123",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 머신러닝 모델\n",
    "# k-최근접 이웃 알고리즘\n",
    "# 훈련 데이터에서 새로운 데이터 포인트에 가장 가까운 'k개'의 이웃을 찾는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1594825380404,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "1dUHgf2h7vZ7",
    "outputId": "541c99e7-adf7-4c93-bf11-328358d883cc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 예측하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1594825386144,
     "user": {
      "displayName": "oz To",
      "photoUrl": "",
      "userId": "12937505880450462933"
     },
     "user_tz": -540
    },
    "id": "G745Zuh39PXq",
    "outputId": "edb6816b-3477-4b7e-dfef-9866bb0c7175",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "# 테스트 세트 이용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### KNeighborsClassifier 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 결정경계([descision boundary](https://developers.google.com/machine-learning/glossary#%EA%B2%B0%EC%A0%95-%EA%B2%BD%EA%B3%84decision-boundary))\n",
    "\n",
    "이웃의 수를 늘릴수록 결정경계는 더 부드러워진다.\n",
    "\n",
    "이웃을 적게 사용하면 모델의 복잡도가 높아지고, \n",
    "많이 사용하면 복잡도는 낮아진다."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyPryx1PjQ1zFG0Ep6nfP+/6",
   "collapsed_sections": [],
   "name": "ml_02_지도학습_KNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
